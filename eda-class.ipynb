{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pandas into Python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reading-files\"></a>\n",
    "### Reading Files, Selecting Columns, and Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  #print working directory, so you can traverse to where your files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user.tbl', sep='|') # default value for \"sep\" keywork is ',' sep is how your data is separated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the users data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users                   # Prints the first 30 and last 30 rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_users)             # DataFrame class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head()            # Print the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head(10)          # Print the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.tail()            # Print the last five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The row index (aka \"the row labels\" — in this case integers)\n",
    "df_users.index            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names (which is \"an index\")\n",
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes of each column — each column is stored as an ndarray, which has a datatype\n",
    "df_users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns\n",
    "df_users.shape                                  # returns a tuple of (Rows, Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values as a NumPy array\n",
    "df_users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concise summary (including memory usage) — useful to quickly see if nulls exist\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Select or index data.**<br>\n",
    "Pandas `DataFrame`s have structural similarities with Python-style lists and dictionaries.  \n",
    "In the example below, we select a column of data using the name of the column in a similar manner to how we select a dictionary value with the dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column — returns a Pandas Series (essentially an ndarray with an index)\n",
    "df_users['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users[['gender']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns are Pandas Series.\n",
    "type(df_users['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_users[['gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column using the DataFrame attribute.\n",
    "df_users.gender.head()\n",
    "\n",
    "# While a useful shorthand, these attributes only exist\n",
    "# if the column name has no punctuations or spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarize (describe) the data.**<br>\n",
    "Pandas has a bunch of built-in methods to quickly summarize your data and provide you with a quick general understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all numeric columns (statistical type summary).\n",
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all object columns (can include multiple types).\n",
    "df_users.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_desc = df_users.describe(include=['object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column to the object description dataframe\n",
    "df_obj_desc['zip_counts'] = [len(df_obj_desc.zip_code), 19, 45, 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all columns, including non-numeric.\n",
    "df_users.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe a single column — recall that \"users.gender\" refers to a Series.\n",
    "df_users.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the ages.\n",
    "df_users.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a histogram of a column (the distribution of ages).\n",
    "df_users.age.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of occurrences of each value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.gender.value_counts()     # Most useful for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.gender.value_counts().plot(kind='bar')     # Quick plot by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be used with numeric variables\n",
    "#   Try .sort_index() to sort by indices or .sort_values() to sort by counts.\n",
    "df_users.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.age.value_counts().sort_index().plot(kind='bar', figsize=(12,12));     # Bigger plot by increasing age\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Number of users');\n",
    "plt.title('Number of users per age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-one\"></a>\n",
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read drinks.csv into a DataFrame called \"drinks\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head and the tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the default index, datatypes, and shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the beer_servings Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average beer_servings for the entire data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each \"continent\" value and see if it looks correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering-and-sorting\"></a>\n",
    "### Filtering and Sorting\n",
    "- **Objective:** Filter and sort data using Pandas.\n",
    "\n",
    "We can use simple operator comparisons on columns to extract relevant or drop irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering: Only show users with age < 20.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series of Booleans…\n",
    "# In Pandas, this comparison is performed element-wise on each row of data.\n",
    "mask = df_users['age'] < 20\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# …and use that Series to filter rows.\n",
    "# In Pandas, indexing a DataFrame by a Series of Booleans only selects rows that are True in the Boolean.\n",
    "mask = df_users.age < 20\n",
    "df_users[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, combine into a single step.\n",
    "mask = df_users.occupation == 'student'\n",
    "#Use .copy() so that resulting sub df is mutable\n",
    "df_student = df_users[mask].copy()\n",
    "df_student.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: This creates a view of the original DataFrame, not a new DataFrame.\n",
    "# If you alter this view (e.g., by storing it in a variable and altering that)\n",
    "# You will alter only the slice of the DataFrame and not the actual DataFrame itself\n",
    "# Here, notice that Pandas gives you a SettingWithCopyWarning to alert you of this.\n",
    "\n",
    "# It is best practice to use .loc and .iloc instead of the syntax below\n",
    "\n",
    "df_student['age'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student.age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column from the filtered results.\n",
    "#student_frame.iloc[:5, :2]\n",
    "df_users.loc[8, 'age'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts of resulting Series\n",
    "df_users.gender.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ampersand for `AND` condition. (This is a \"bitwise\" `AND`.)\n",
    "# Important: You MUST put parentheses around each expression because `&` has a higher precedence than `<`.\n",
    "df_drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe for `OR` condition. (This is a \"bitwise\" `OR`.)\n",
    "# Important: You MUST put parentheses around each expression because `|` has a higher precedence than `<`.\n",
    "mask = (df_drinks.beer_servings > 25) & (df_drinks.continent == 'EU')\n",
    "df_drinks[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_drinks.beer_servings > 25) & (df_drinks.continent == 'EU') | (df_drinks.wine_servings > 200)\n",
    "df_drinks[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferred alternative to multiple `OR` conditions\n",
    "#users[users.occupation.isin(['doctor', 'lawyer'])]\n",
    "df_users[['age', 'gender', 'occupation']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = ['a', 'b', 'c', 10]\n",
    "for entry in alist:\n",
    "    if entry in df_users.age:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a Series.\n",
    "df_users.age.sort_values().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.age.sort_values().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user.tbl',sep='|')\n",
    "#df_users = df_users.age.sort_values().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a DataFrame by a single column.\n",
    "ds_age = df_users.age.copy()\n",
    "# View the internal python id value of the ds_age object\n",
    "id(ds_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id(df_users.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_age.sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use descending order instead.\n",
    "df_users.sort_values('age', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.sort_values('age').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by multiple columns.\n",
    "df_users.sort_values(['occupation', 'age'], ascending = [True, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-two\"></a>\n",
    "### Exercise 2\n",
    "Use the `drinks.csv` or `drinks` `DataFrame` from earlier to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to only include European countries.\n",
    "df_drinks[df_drinks.continent == 'EU'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to only include European countries with wine_servings > 300.\n",
    "df_drinks[(df_drinks.continent == 'EU') & (df_drinks.wine_servings > 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average beer_servings for all of Europe.\n",
    "mask = df_drinks.continent == 'EU'\n",
    "df_drinks[mask]['beer_servings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which 10 countries have the highest total_litres_of_pure_alcohol.\n",
    "df_big_drinkers = df_drinks.nlargest(10, 'total_litres_of_pure_alcohol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_drinkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks_sub = df_drinks.sort_values('total_litres_of_pure_alcohol', ascending = False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id(df_drinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks_sub.beer_servings = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"columns\"></a>\n",
    "### Renaming, Adding, and Removing Columns\n",
    "\n",
    "- **Objective:** Manipulate `DataFrame` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column labels\n",
    "print(df_drinks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns in a single output using value mapping.\n",
    "df_drinks = df_drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns in the original DataFrame.\n",
    "df_drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all column names using a list of matching length.\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'liters', 'continent'] \n",
    "\n",
    "# Replace during file reading (disables the header from the file).\n",
    "df_drinks = pd.read_csv('data/drinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.columns = drink_cols\n",
    "df_drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace after file has already been read into Python.\n",
    "df_drinks.columns = drink_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easy Column Operations**<br>\n",
    "Rather than having to reference indexes and create for loops to do column-wise operations, Pandas is smart and knows that when we add columns together we want to add the values in each row together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column as a function of existing columns.\n",
    "df_drinks['servings'] = df_drinks.beer + df_drinks.spirit + df_drinks.wine\n",
    "df_drinks['mL'] = df_drinks.liters * 1000\n",
    "\n",
    "df_drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks = df_drinks.drop(13).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.iloc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In old versions of pandas, axes were indicated with 0s and 1s.  If you ever see\n",
    "# axis=0 for rows, 1 for columns -> this is leftover from older versioning.\n",
    "# Now, axes are indicated by \"columns\" or \"index\"\n",
    "\n",
    "# Drop multiple columns.\n",
    "df_drinks.drop(['mL', 'servings'], axis='columns').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop on the original DataFrame rather than returning a new one.\n",
    "df_drinks.drop(['mL', 'servings'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-values\"></a>\n",
    "### Handling Missing Values\n",
    "\n",
    "- **Objective:** Know how to handle null and missing values.\n",
    "\n",
    "Sometimes, values will be missing from the source data or as a byproduct of manipulations. It is very important to detect missing data. Missing data can:\n",
    "\n",
    "- Make the entire row ineligible to be training data for a model.\n",
    "- Hint at data-collection errors.\n",
    "- Indicate improper conversion or manipulation.\n",
    "- Actually not be missing — it sometimes means \"zero,\" \"false,\" \"not applicable,\" or \"entered an empty string.\"\n",
    "\n",
    "For example, a `.csv` file might have a missing value in some data fields:\n",
    "\n",
    "```\n",
    "tool_name,material,cost\n",
    "hammer,wood,8\n",
    "chainsaw,,\n",
    "wrench,metal,5\n",
    "```\n",
    "\n",
    "When this data is imported, \"null\" values will be stored in the second row (in the \"material\" and \"cost\" columns).\n",
    "\n",
    "> In Pandas, a \"null\" value is either `None` or `np.NaN` (Not a Number). Many fixed-size numeric datatypes (such as integers) do not have a way of representing `np.NaN`. So, numeric columns will be promoted to floating-point datatypes that do support it. For example, when importing the `.csv` file above:\n",
    "\n",
    "> - **For the second row:** `None` will be stored in the \"material\" column and `np.NaN` will be stored in the \"cost\" column. The entire \"cost\" column (stored as a single `ndarray`) must be stored as floating-point values to accommodate the `np.NaN`, even though an integer `8` is in the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values are usually excluded in calculations by default.\n",
    "df_drinks.continent.value_counts()              # Excludes missing values in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes missing values\n",
    "df_drinks.continent.value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in a Series.\n",
    "# True if missing, False if not missing\n",
    "df_drinks.continent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the missing values — sum() works because True is 1 and False is 0.\n",
    "df_drinks.continent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if not missing, False if missing\n",
    "mask = df_drinks.continent.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show rows where continent is not missing.\n",
    "df_drinks[df_drinks.continent.notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Pandas Axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"down\" the 0 axis (rows) — so, we get the sums of each column\n",
    "df_drinks.sum(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=0 is the default.\n",
    "df_drinks.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"across\" the 1 axis (columns) — so, we get the sums of numeric values in the row (beer+spirit+wine+liters+…)\n",
    "df_drinks['wine_liters'] = df_drinks[['wine', 'liters']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.wine_liters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find missing values in a `DataFrame`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of Booleans\n",
    "df_drinks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_drinks.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.isnull().sum().plot(kind='bar');         # visually\n",
    "plt.title('Number of null values per column');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row if ANY values are missing from any column — can be dangerous!\n",
    "df_drinks.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row only if ALL values are missing.\n",
    "df_drinks.dropna(how='all').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling Missing Values**<br>\n",
    "You may have noticed that the continent North America (NA) does not appear in the `continent` column. Pandas read in the original data and saw \"NA\", thought it was a missing value, and converted it to a `NaN`, missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_drinks[df_drinks.continent.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with \"NA\" — this is dangerous to do without manually verifying them!\n",
    "df_drinks = pd.read_csv('data/drinks.csv')\n",
    "df_drinks['continent'] = df_drinks.continent.fillna(value='NA').copy()\n",
    "len(df_drinks[df_drinks.continent.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies \"drinks\" in-place\n",
    "df_drinks.continent.fillna(value='NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the missing value filter — this is a better approach!\n",
    "df_drinks = pd.read_csv('data/drinks.csv', header=0, names=drink_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.continent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-three\"></a>\n",
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ufo.csv into a DataFrame called \"ufo\".\n",
    "file_path = 'data/ufo.csv'\n",
    "df_ufo = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame.\n",
    "df_ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the three most common colors reported?\n",
    "df_ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ufo['Colors Reported'].value_counts().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename any columns with spaces so that they don't contain spaces.\n",
    "df_ufo.columns = [col.replace(' ','') for col in df_ufo.columns]\n",
    "df_ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reports in VA, what's the most common city?\n",
    "df_ufo[df_ufo.State=='VA'].City.value_counts().sort_values(ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a DataFrame containing only reports from Arlington, VA.\n",
    "mask = (df_ufo.City=='Arlington') & (df_ufo.State=='VA')\n",
    "df_ufo[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values in each column.\n",
    "df_ufo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows remain if you drop all rows with any missing values?\n",
    "len(df_ufo.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split-apply-combine\"></a>\n",
    "### Split-Apply-Combine\n",
    "\n",
    "Split-apply-combine is a pattern for analyzing data. Suppose we want to find mean beer consumption per country. Then:\n",
    "\n",
    "- **Split:** We group data by continent.\n",
    "- **Apply:** For each group, we apply the `mean()` function to find the average beer consumption.\n",
    "- **Combine:** We now combine the continent names with the `mean()`s to produce a summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, calculate the mean beer servings.\n",
    "df_drinks = df_drinks.rename(columns={'beer_servings':'beer'}).copy()\n",
    "df_drinks.groupby('continent').beer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, calculate the mean of all numeric columns.\n",
    "df_drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, describe beer servings.\n",
    "df_drinks.groupby('continent').beer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar, but outputs a DataFrame and can be customized — \"agg\" allows you to aggregate results of Series functions\n",
    "df_drinks.groupby('continent').beer.agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drinks.groupby('continent').beer.agg(['count', 'mean', 'min', 'max']).sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, describe all numeric columns.\n",
    "df_drinks.groupby('continent').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, count the number of rows.\n",
    "print((df_drinks.groupby('continent').continent.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_drinks.continent.value_counts()))   # should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-four\"></a>\n",
    "### Exercise 4\n",
    "\n",
    "Use the \"users\" `DataFrame` or \"users\" file in the Data folder to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation in \"users\", count the number of occurrences.\n",
    "df_users.groupby('occupation').user_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation, calculate the mean age.\n",
    "df_users.groupby('occupation').age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation, calculate the minimum and maximum ages.\n",
    "df_users.groupby('occupation').age.agg(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each combination of occupation and gender, calculate the mean age.\n",
    "df_users.groupby(['occupation','gender']).age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multiple-columns\"></a>\n",
    "### Selecting Multiple Columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns — yet another overload of the DataFrame indexing operator!\n",
    "my_cols = ['City', 'State']     # Create a list of column names...\n",
    "df_ufo[my_cols].head()          # ...and use that list to select columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, combine into a single step (this is a Python list inside of the Python index operator!).\n",
    "df_ufo[['City', 'State']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `loc` to select columns by name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two columns.\n",
    "df_ufo.loc[:, ['City', 'State']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 0/1/2, range of columns\n",
    "df_ufo.loc[0:2, 'City':'State'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For more on using .loc and .iloc, see `loc_iloc_examples.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"joining-dataframes\"></a>\n",
    "### Joining (Merging) `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movie_cols = ['movie_id', 'title']\n",
    "movies_file_path = 'data/movies.tbl'\n",
    "\n",
    "df_movies = pd.read_table(\n",
    "    movies_file_path,\n",
    "    sep='|',\n",
    "    header=None,\n",
    "    names=movie_cols,\n",
    "    usecols=[0, 1],\n",
    "    encoding='latin-1')\n",
    "\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings_file_path = 'data/movie_ratings.tsv'\n",
    "\n",
    "df_ratings = pd.read_csv(ratings_file_path, sep='\\t', header=None, names=rating_cols)\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \"movies\" and \"ratings\" (inner join on \"movie_id\" by default).\n",
    "df_movie_ratings = pd.merge(df_movies, df_ratings)\n",
    "df_movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies.shape)\n",
    "print(df_ratings.shape)\n",
    "print(df_movie_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other-features\"></a>\n",
    "### OPTIONAL: Other Commonly Used Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an arbitrary function to each value of a Pandas column, storing the result in a new column.\n",
    "df_users['under30'] = df_users.age.apply(lambda age: age < 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an arbitrary function to each row of a DataFrame, storing the result in a new column.\n",
    "#  (Remember that, by default, axis=0. Since we want to go row by row, we set axis=1.)\n",
    "df_users['under30male'] = df_users.apply(lambda row: row.age < 30 and row.gender == 'M', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map existing values to a different set of values.\n",
    "df_users['is_male'] = df_users.gender.map({'F':0, 'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all instances of a value in a column (must match entire value).\n",
    "df_ufo.State.replace('Fl', 'FL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String methods are accessed via \"str\".\n",
    "df_ufo.State.str.upper()                               # Converts to upper case\n",
    "# checks for a substring\n",
    "df_ufo['Colors Reported'].str.contains('RED', na='False') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string to the datetime format (this is often slow — consider doing it in the \"read_csv()\" method.)\n",
    "df_ufo['Time'] = pd.to_datetime(df_ufo.Time)\n",
    "df_ufo.Time.dt.hour                        # Datetime format exposes convenient attributes\n",
    "(df_ufo.Time.max() - df_ufo.Time.min()).days  # Also allows you to do datetime \"math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and then remove an index.\n",
    "df_ufo.set_index('Time', inplace=True)\n",
    "df_ufo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of a column.\n",
    "df_drinks['beer'] = df_drinks.beer.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for \"continent\" and exclude first dummy column.\n",
    "df_continent_dummies = pd.get_dummies(df_drinks.continent, prefix='cont').iloc[:, 1:]\n",
    "df_continent_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two DataFrames (axis=0 for rows, axis=1 for columns).\n",
    "df_drinks = pd.concat([df_drinks, df_continent_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"uncommon-features\"></a>\n",
    "### OPTIONAL: Other Less-Used Features of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting duplicate rows\n",
    "df_users.duplicated()          # True if a row is identical to a previous row\n",
    "df_users.duplicated().sum()    # Count of duplicates\n",
    "df_users[df_users.duplicated()]   # Only show duplicates\n",
    "df_users.drop_duplicates()     # Drop duplicate rows\n",
    "df_users.age.duplicated()      # Check a single column for duplicates\n",
    "df_users.duplicated(['age', 'gender', 'zip_code']).sum()   # Specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a range of values into descriptive groups.\n",
    "df_drinks['beer_level'] = 'low'    # Initially set all values to \"low\"\n",
    "df_drinks.loc[df_drinks.beer.between(101, 200), 'beer_level'] = 'med'     # Change 101-200 to \"med\"\n",
    "df_drinks.loc[df_drinks.beer.between(201, 400), 'beer_level'] = 'high'    # Change 201-400 to \"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a cross-tabulation of two Series.\n",
    "pd.crosstab(df_drinks.continent, df_drinks.beer_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"beer_level\" into the \"category\" datatype.\n",
    "df_drinks['beer_level'] = pd.Categorical(df_drinks.beer_level, categories=['low', 'med', 'high'])\n",
    "df_drinks.sort_values('beer_level').head()   # Sorts by the categorical ordering (low to high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit which rows are read when reading in a file — useful for large files!\n",
    "pd.read_csv('data/drinks.csv', nrows=10)           # Only read first 10 rows\n",
    "pd.read_csv('data/drinks.csv', skiprows=[1, 2])    # Skip the first two rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a DataFrame out to a .csv\n",
    "df_drinks.to_csv('data/drinks_updated.csv')                 # Index is used as first column\n",
    "df_drinks.to_csv('data/drinks_updated.csv', index=False)    # Ignore index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary.\n",
    "pd.DataFrame({'capital':['Montgomery', 'Juneau', 'Phoenix'], 'state':['AL', 'AK', 'AZ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a list of lists.\n",
    "pd.DataFrame([['Montgomery', 'AL'], ['Juneau', 'AK'], ['Phoenix', 'AZ']], columns=['capital', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a DataFrame.\n",
    "import numpy as np\n",
    "mask = np.random.rand(len(df_drinks)) < 0.66   # Create a Series of Booleans\n",
    "df_train = df_drinks[mask]                        # Will contain around 66% of the rows\n",
    "df_test = df_drinks[~mask]                        # Will contain the remaining rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Pandas default options\n",
    "# Change the maximum number of rows and columns printed ('None' means unlimited).\n",
    "pd.set_option('max_rows', None)     # Default is 60 rows (first and last 30)\n",
    "pd.set_option('max_columns', None)  # Default is 20 columns (first and last 10)\n",
    "print(df_drinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset options to defaults.\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the options temporarily (settings are restored when you exit the \"with\" block).\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print(df_drinks)\n",
    "print(df_drinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "### Summary\n",
    "\n",
    "Believe it or not, we've only barely touched the surface of everything that Pandas offers. Don't worry if you don't remember most of it — for now, just knowing what exists is key. Remember that the more you use Pandas to manipulate data, the more of these functions you will take interest in, look up, and remember.\n",
    "\n",
    "In this notebook, the most important things to familiarize yourself with are the basics:\n",
    "- Manipulating `DataFrames` and `Series`\n",
    "- Filtering columns and rows\n",
    "- Handling missing values\n",
    "- Split-apply-combine (this one takes some practice!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
